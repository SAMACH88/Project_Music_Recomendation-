# -*- coding: utf-8 -*-
"""MusicRecomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kmNZb17mHgxALU68pClbkXk5IbiFCFw7
"""

import numpy as np
import pandas as pd

import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt

data=pd.read_csv('/content/drive/MyDrive/Datasets/DataSpotify.csv')
data_genres=pd.read_csv('/content/drive/MyDrive/Datasets/data_by_genres.csv')
data_year=pd.read_csv('/content/drive/MyDrive/Datasets/data_by_year.csv')
data_artist=pd.read_csv('/content/drive/MyDrive/Datasets/data_by_artist.csv')

"""***Step 1: Load and explore the Spotify dataset for further analysis and processing.***"""

data.head()

data.info()

data.describe()

print(data.head(2))

data['decade'] = data['year'].apply(lambda x: (x // 10) * 10)

print(data.head(2))

"""***Step2: Perform exploratory data analysis on the Spotify dataset to gain insights into various aspects of the music data.***"""

##!pip install --upgrade plotly

"""*Visualize the distribution of tracks across different decades using a count plot: sns.countplot(data['decade']).*"""

import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

palette = sns.color_palette("husl", len(data['decade'].unique()))
sns.countplot(data=data, x='decade',palette=palette)
plt.xlabel('Decade')
plt.ylabel('Number of Tracks')
plt.title('Distribution of Tracks Across Different Decades')
plt.show()

sound_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'valence']
data['decade'] = (data['year'] // 10) * 10

# Calculate the mean for only the numeric sound features
aggregated_data = data.groupby('decade')[sound_features].mean().reset_index()

fig = px.line(aggregated_data, x='decade', y=sound_features,
              title='Trend of Various Sound Features Over Decades (Aggregated)')
fig.show()

data['decade'] = (data['year'] // 10) * 10

# Aggregating loudness by decade
aggregated_data = data.groupby('decade')['loudness'].mean().reset_index()

# Plot the aggregated loudness data
fig = px.line(aggregated_data, x='decade', y='loudness',
              title='Trend of Loudness Over Decades (Aggregated)')
fig.show()

top_genres = data_genres.groupby('genres')['popularity'].mean().nlargest(10).index


top10_genres =data_genres[data_genres['genres'].isin(top_genres)].groupby('genres')[
    ['valence', 'energy', 'danceability', 'acousticness']].mean().reset_index()


fig = px.bar(top10_genres,
             x='genres',
             y=['valence', 'energy', 'danceability', 'acousticness'],
             barmode='group',
             title='Trend of Various Sound Features Over Top 10 Genres')

fig.show()

!pip install wordcloud matplotlib

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter

comment_words = ' '.join(data_genres)
wordcloud = WordCloud(width=800, height=800, background_color='white',
                      stopwords=None, max_words=40, min_font_size=10).generate(comment_words)

# Plot the word cloud
plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=0)

# Show the word cloud
plt.show()

plt.imshow(wordcloud)

from wordcloud import WordCloud, STOPWORDS
# Combine all artist names into a single string
comment_words = ' '.join(data_artist)

# Define stopwords (optional, you can customize or leave it to default STOPWORDS)
stopwords = set(STOPWORDS)

# Create the WordCloud object
wordcloud = WordCloud(width=800, height=800, background_color='white',
                      stopwords=stopwords, max_words=40, min_font_size=10,
                      min_word_length=3).generate(comment_words)

# Plot the word cloud
plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=0)

# Show the word cloud
plt.show()

plt.imshow(wordcloud, interpolation="bilinear")

artist_song_count = data_artist['artists'].value_counts().reset_index()

# Rename the columns for better clarity
artist_song_count.columns = ['artists', 'count']

# Get the top 10 artists
top10_most_song_produced_artists = artist_song_count.head(10)

# Display the top 10 artists sorted by the count in descending order
print(top10_most_song_produced_artists[['count', 'artists']].sort_values('count', ascending=False))

top10_popular_artists = data_artist[['artists', 'popularity']].sort_values('popularity', ascending=False).head(10)
print(top10_popular_artists)

"""Based on the results in the table, we can conclude:
1)Top Artists by Popularity: The top 10 artists, according to their popularity scores, include names such as Ritt Momney
2)Diverse Popularity: The popularity scores of the top 10 artists are relatively close to each other, with a maximum of 93.0 and a minimum of 86.0
3) genres mode impact:When analyzing the word cloud for genres or artists, the genres and mode impact.

***Step 3: Fit a K-means clustering model on the genre data using 12 clusters. Assign the cluster labels to each genre.***
"""

from sklearn.cluster import KMeans
from sklearn.preprocessing import OneHotEncoder

X = data_genres.copy()

categorical_cols = X.select_dtypes(include=['object']).columns

encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
encoded_data = encoder.fit_transform(X[categorical_cols])

encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))

X = encoded_df

data_genres.info()

data_genres.head()

kmeans = KMeans(n_clusters=12, random_state=42, n_init=10)
kmeans.fit(X)

X['Cluster'] = kmeans.fit_predict(X)

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

if 'genres' in X.columns:
    X = X.drop(columns=['genres'])
tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)
tsne_results = tsne.fit_transform(X.drop(columns=['Cluster']))

# Create a new DataFrame for visualization
tsne_df = pd.DataFrame()
tsne_df['tsne_1'] = tsne_results[:, 0]
tsne_df['tsne_2'] = tsne_results[:, 1]
tsne_df['Cluster'] = X['Cluster']

genre_columns = [col for col in X.columns if col != 'Cluster']

fig = px.scatter(tsne_df, x='tsne_1', y='tsne_2', color='Cluster',
                 hover_data=['Cluster'],  # Only display the 'Cluster' column on hover
                 title='t-SNE Visualization of Genre Clusters')

fig.show()

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

##DF = X.drop('Cluster', axis=1)

# Standardize the data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(X)
#Apply PCA to reduce dimensions
pca = PCA(n_components=2)
pca_components = pca.fit_transform(scaled_features)



# Perform clustering
kmeans = KMeans(n_clusters=12)  # Adjust number of clusters as needed
clusters = kmeans.fit_predict(pca_components)

# Add PCA components and cluster labels to the DataFrame
X['PCA1'] = pca_components[:, 0]
X['PCA2'] = pca_components[:, 1]
X['Cluster'] = clusters

print(X.head())

fig = px.scatter(X, x='PCA1', y='PCA2', color='Cluster',
                 hover_data=['Cluster', 'genres_[]'])

#  Display the plot
fig.show()

"""# **Step 4:  build a recommendation system that suggests similar songs based on user input.**"""

!pip install spotipy

# Commented out IPython magic to ensure Python compatibility.
# %env SPOTIPY_CLIENT_ID='your_client_id_here'
# %env SPOTIPY_CLIENT_SECRET='your_client_secret_here'

!pip install kaggle_secrets

# Import necessary libraries
import spotipy
import os
from spotipy.oauth2 import SpotifyClientCredentials
from collections import defaultdict
#from kaggle_secrets import UserSecretsClient
import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import numpy as np

# Step 1: Retrieve the credentials from environment variables
client_id = os.getenv('SPOTIPY_CLIENT_ID')
client_secret = os.getenv('SPOTIPY_CLIENT_SECRET')
# Step 2: Set up Spotify client credentials
spotify_credentials = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)
sp = spotipy.Spotify(client_credentials_manager=spotify_credentials)

!pip install python-dotenv

!pip install requests

import os
from dotenv import load_dotenv

load_dotenv()
client_id = os.getenv
client_secret = 'your_client_secret_here'

# Commented out IPython magic to ensure Python compatibility.
# %env SPOTIPY_CLIENT_ID='00d989797cab401f80051ebc53e8d028'
# %env SPOTIPY_CLIENT_SECRET='1f714a6b7d634c7398bcc902f1dcc5bb'

print("Client ID:", client_id)
print("Client Secret:", client_secret)

# Manually set the credentials (for testing purposes)
client_id = '00d989797cab401f80051ebc53e8d028'
client_secret = '1f714a6b7d634c7398bcc902f1dcc5bb'

# Print the credentials to verify (remove this before production)
print("Client ID:", client_id)
print("Client Secret:", client_secret)

# Set up Spotify client credentials
spotify_credentials = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)
sp = spotipy.Spotify(client_credentials_manager=spotify_credentials)

# Test the connection
try:
    featured_playlists = sp.featured_playlists()
    for playlist in featured_playlists['playlists']['items']:
        print(f"Playlist Name: {playlist['name']}, Playlist ID: {playlist['id']}")
except spotipy.SpotifyOauthError as e:
    print("Spotify OAuth Error:", e)

import base64
import requests # Import the requests library
import json

def get_token():
    client_id = '00d989797cab401f80051ebc53e8d028'  # Replace with your actual client ID
    client_secret = '1f714a6b7d634c7398bcc902f1dcc5bb'
    auth_string=client_id +":"+client_secret
    auth_bytes=auth_string.encode("utf-8")
    auth_base64=str(base64.b64encode(auth_bytes),"utf-8")

    url="https://accounts.spotify.com/api/token"
    headers={
      "Authorization":"Basic "+auth_base64,
      "Content-Type":"application/x-www-form-urlencoded"
    }  #Fixed indentation here
    data={"grant_type":"client_credentials"} #Fixed indentation here
    result=requests.post(url, headers=headers,data=data) # Use requests.post()
    json_result=json.loads(result.content)
    token=json_result["access_token"]
    return token

token=get_token()
print(token)

def search_for_song(token,song_name):
    url="https://api.spotify.com/v1/search"
    headers={
           "Authorization":"Bearer {}".format(token)
           }
    query=f"q={song_name}&type=track"
    query_url=url + "?" + query
    result=requests.get(query_url, headers=headers)
    json_result=json.loads(result.content)["tracks"]["items"] # Access the 'tracks' key to get the list of tracks
    if len(json_result)==0:
        print("No song found")
    else:
        song_id=json_result[0]["id"]
        return song_id # Return the song ID if found

    print(json_result)

token=get_token()
search_for_song(token,"Shape of You")

def get_mean_vector(songs):
    if not songs:
        print("No songs provided")
        return None

    # Initialize an empty list to store feature vectors
    feature_vectors = []  # Ensure this line has consistent indentation (4 spaces is recommended)

    # Extract feature vectors from each song
    for song in songs:
        if isinstance(song, dict):
            try:
                # Convert song features into a numpy array
                vector = np.array(list(song.values()))
                feature_vectors.append(vector)
            except Exception as e:
                print(f"Error processing song: {e}")
                return None
        else:
            print(f"Invalid song format: {song}")
            return None

    # Convert the list of feature vectors to a numpy array
    feature_vectors = np.array(feature_vectors)

    # Calculate the mean vector
    mean_vector = np.mean(feature_vectors, axis=0)

    return mean_vector

get_mean_vector("Shape of You")

dict_list = [
    {'Peaceful Piano': 1.2, 'shape of you': 3.4, 'This Is Zach Bryan': 5.6},
    {'Peaceful Piano': 2.3, 'shape of you': 4.5, 'This Is Zach Bryan': 6.7},
    {'Peaceful Piano': 0.9, 'shape of you': 3.2, 'This Is Zach Bryan': 5.4}
]
def flatten_dict_list(dict_list):

    if not dict_list:
        print("The list of dictionaries is empty.")
        return None

    # Initialize an empty dictionary to store the flattened result
    flattened_dict = {}

    # Iterate over each dictionary in the list
    for d in dict_list:
        if isinstance(d, dict):
            for key, value in d.items():
                if key in flattened_dict:
                    flattened_dict[key].append(value)
                else:
                    flattened_dict[key] = [value]
        else:
            print(f"Invalid item in list, expected dictionary but got {type(d).__name__}.")
            return None

    return flattened_dict

"""Define a function recommend_songs that recommends similar songs based on a given list of songs."""

from sklearn.metrics.pairwise import cosine_similarity

given_songs = [
    {'Peaceful Piano': 1.2, 'shape of you': 3.4, 'This Is Zach Bryan': 5.6},
    {'Peaceful Piano': 2.3, 'shape of you': 4.5, 'This Is Zach Bryan': 6.7}
]

all_songs = [
    {'Peaceful Piano': 0.9, 'shape of you': 3.2, 'This Is Zach Bryan': 5.4},
    {'Peaceful Piano': 2.8, 'shape of you': 4.9, 'This Is Zach Bryan': 7.1},
    {'Peaceful Piano': 1.1, 'shape of you': 3.5, 'This Is Zach Bryan': 5.7},
    {'Peaceful Piano': 2.2, 'shape of you': 4.4, 'This Is Zach Bryan': 6.6},
    {'Peaceful Piano': 1.0, 'shape of you': 3.3, 'This Is Zach Bryan': 5.5}
]

def recommend_songs(given_songs, all_songs, top_n=5):
    if not given_songs or not all_songs:
        print("Insufficient songs data provided")
        return None

    # Step 1: Calculate the mean vector of the given songs
    mean_vector = get_mean_vector(given_songs) # Check indentation of this line and ensure it's consistent with the rest of the function
    if mean_vector is None:
        return None

    # Step 2: Calculate similarities between the mean vector and all songs
    similarities = []
    for song in all_songs:
        if isinstance(song, dict):
            try:
                song_vector = np.array(list(song.values()))
                similarity = cosine_similarity([mean_vector], [song_vector])[0][0]
                similarities.append((similarity, song))
            except Exception as e:
                print(f"Error processing song: {e}")
                continue
        else:
            print(f"Invalid song format: {song}")
            continue

    # Step 3: Sort the songs by similarity and select the top N recommendations
    similarities.sort(reverse=True, key=lambda x: x[0])
    recommended_songs = [song for _, song in similarities[:top_n]]

    return recommended_songs

"""Implement the recommendation system by following the instructions provided within each function."""

# Get recommended songs
recommended_songs = recommend_songs(given_songs, all_songs, top_n=3)
if recommended_songs is not None:
    print("Recommended Songs:")
    for song in recommended_songs:
        print(song)

# Get recommendations
given_songs_1 = given_songs # Assuming you want to use the same given_songs as before
recommended_songs_1 = recommend_songs(given_songs_1, all_songs, top_n=3) # Also using the original all_songs
print("Test Case 1 - Recommended Songs:")
for song in recommended_songs_1:
    print(song)
print("\n")